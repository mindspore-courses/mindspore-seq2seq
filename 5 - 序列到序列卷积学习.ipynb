{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - 序列到序列卷积学习\n",
    "\n",
    "在这个笔记本中，我们将实现[卷积序列到序列学习](https://arxiv.org/abs/1705.03122)模型。\n",
    "\n",
    "注意！本笔记本需要 mindspore 高于  2.2.10 版本运行。低版本存在view机制错误导致梯度丢失，训练过程中梯度丢失导致loss不变。\n",
    "\n",
    "![](assets/convseq2seq0.png)\n",
    "\n",
    "## 简介\n",
    "\n",
    "这个模型与这些教程中先前使用的模型截然不同。它根本没有使用循环组件。相反，它使用卷积层，通常用于图像处理。有关在文本情感分析中使用卷积层的介绍，请参见[此](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb)教程。\n",
    "\n",
    "简而言之，卷积层使用*过滤器*。这些过滤器具有*宽度*（在图像中还有*高度*，但通常不适用于文本）。如果一个过滤器的宽度为3，那么它可以查看3个连续的标记。每个卷积层有许多这些过滤器（在本教程中为1024）。每个过滤器将沿着序列滑动，从开始到结束，一次查看3个连续的标记。这些1024个过滤器中的每一个都将学会从文本中提取不同的特征。这个特征提取的结果将由模型使用 - 可能作为输入到另一个卷积层。然后，所有这些都可以用于从源句中提取特征，以将其翻译成目标语言。\n",
    "\n",
    "## 准备数据\n",
    "\n",
    "首先，让我们导入所有必需的模块并设置用于可重复性的随机种子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "import mindspore.context as context\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from functools import partial\n",
    "\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import spacy\n",
    "import datasets\n",
    "from tqdm.notebook import tqdm\n",
    "import evaluate as evaluate_hf\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "ms.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入数据集，不再赘述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/root/.cache/huggingface/datasets/bentrevett___json/bentrevett--multi30k-8cca6da32304eb4d/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5677af03f7ae473eb7d3fdfbb4c9732a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/bentrevett___json/bentrevett--multi30k-8cca6da32304eb4d/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-39e2a81dd5826464.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/bentrevett___json/bentrevett--multi30k-8cca6da32304eb4d/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-340eed13fdfe768e.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/bentrevett___json/bentrevett--multi30k-8cca6da32304eb4d/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-05a87c7dda3754fe.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"bentrevett/multi30k\")\n",
    "train_data, valid_data, test_data = dataset[\"train\"], dataset[\"validation\"], dataset[\"test\"]\n",
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "de_nlp = spacy.load(\"de_core_news_sm\")\n",
    "def tokenize_example(\n",
    "    example,\n",
    "    en_nlp,\n",
    "    de_nlp,\n",
    "    max_length,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token\n",
    "):\n",
    "    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n",
    "    de_tokens = [token.text for token in de_nlp.tokenizer(example[\"de\"])][:max_length]\n",
    "    if lower:\n",
    "        en_tokens = [token.lower() for token in en_tokens]\n",
    "        de_tokens = [token.lower() for token in de_tokens]\n",
    "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
    "    de_tokens = [sos_token] + de_tokens + [eos_token]\n",
    "    return {\"en_tokens\": en_tokens, \"de_tokens\": de_tokens}\n",
    "\n",
    "\n",
    "max_length = 1_000\n",
    "lower = True\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "fn_kwargs = {\n",
    "    \"en_nlp\": en_nlp, \n",
    "    \"de_nlp\": de_nlp, \n",
    "    \"max_length\": max_length,\n",
    "    \"lower\": lower,\n",
    "    \"sos_token\": sos_token,\n",
    "    \"eos_token\": eos_token,\n",
    "}\n",
    "\n",
    "\n",
    "train_data = train_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(tokenize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "class Vocab:\n",
    "    \"\"\"一个词汇表的实现\"\"\"\n",
    "    def __init__(self, tokens:list, min_freq=0, reserved_tokens:list=None) -> None:\n",
    "        self.default_index = None\n",
    "        if tokens is not None:\n",
    "            # 当第一个条件满足时，就不会跳到第二个判断，避免了空列表报错的情况。\n",
    "            if len(tokens)!=0 and isinstance(tokens[0], list):\n",
    "                tokens = [i for line in tokens for i in line]\n",
    "        else:\n",
    "            tokens = []\n",
    "        if reserved_tokens is None:\n",
    "            reserved_tokens = []\n",
    "        counter=collections.Counter(tokens)\n",
    "        # 按出现词频从高到低排序\n",
    "        self._token_freqs = sorted(counter.items(), key=lambda x:x[1], reverse=True)\n",
    "        # 通过列表,利用序号访问词元。\n",
    "        self.idx_to_token = [] + reserved_tokens # 未知词元<unk>的索引为0, 保留词元排在最前\n",
    "        self.token_to_idx = {\n",
    "            i: k\n",
    "            for k, i in enumerate(self.idx_to_token) \n",
    "        }\n",
    "        \n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:  # 过滤掉出现频率低于要求的词\n",
    "                break\n",
    "            if token not in self.token_to_idx:  \n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "    \n",
    "    def __getitem__(self, input_tokens):\n",
    "        \"\"\"输入单字串或序列, 将其全部转化为序号编码\"\"\"\n",
    "        if isinstance(input_tokens, str):\n",
    "            out =  self.token_to_idx.get(input_tokens, self.default_index)\n",
    "            if out is None:\n",
    "                raise Exception('Please call \"set_default_index\" before getting unknown index')\n",
    "            return out\n",
    "        return [self.__getitem__(token) for token in input_tokens]\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        show_items = 5 if len(self) > 5 else len(self)\n",
    "        out = f\"<Vocab with {len(self)} tokens: \"\n",
    "        for i in range(show_items):\n",
    "            out += f'\"{self.idx_to_token[i]}\", '\n",
    "        out += \"...>\"\n",
    "        return out\n",
    "\n",
    "    def __contains__(self, token:str) -> bool:\n",
    "        return token in self.idx_to_token\n",
    "\n",
    "    def to_tokens(self, input_keys):\n",
    "        \"\"\"输入单s索引或序列, 将其全部转化为词元\"\"\"\n",
    "        if isinstance(input_keys, int):\n",
    "            return self.idx_to_token[input_keys] if input_keys < len(self) else self.idx_to_token[0]\n",
    "        elif isinstance(input_keys, (list, tuple)):\n",
    "            return [self.to_tokens(keys) for keys in input_keys]\n",
    "        else:\n",
    "            return self.idx_to_token[0]\n",
    "    \n",
    "    def get_itos(self):\n",
    "        return self.idx_to_token\n",
    "    \n",
    "    def get_stoi(self):\n",
    "        return self.token_to_idx\n",
    "    \n",
    "    def set_default_index(self, idx):\n",
    "        if isinstance(idx, int):\n",
    "            self.default_index = idx\n",
    "        else:\n",
    "            raise Exception(f\"Only type int allowed, got {type(idx)}\")\n",
    "\n",
    "    def lookup_indices(self, input_tokens):\n",
    "        return self.__getitem__(input_tokens)\n",
    "    \n",
    "    def lookup_tokens(self, idx):\n",
    "        return self.to_tokens(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/bentrevett___json/bentrevett--multi30k-8cca6da32304eb4d/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-6689c04abfdb721f.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/bentrevett___json/bentrevett--multi30k-8cca6da32304eb4d/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-acab783df695b18d.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/bentrevett___json/bentrevett--multi30k-8cca6da32304eb4d/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96/cache-e1088b8589007c26.arrow\n"
     ]
    }
   ],
   "source": [
    "min_freq = 2\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "\n",
    "special_tokens = [\n",
    "    unk_token,\n",
    "    pad_token,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "]\n",
    "\n",
    "def build_vocab_from_iterator(tokens, min_freq, specials):\n",
    "    return Vocab(tokens, min_freq, specials)\n",
    "\n",
    "en_vocab = build_vocab_from_iterator(\n",
    "    train_data[\"en_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")\n",
    "\n",
    "de_vocab = build_vocab_from_iterator(\n",
    "    train_data[\"de_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,  \n",
    ")\n",
    "\n",
    "assert en_vocab[unk_token] == de_vocab[unk_token]\n",
    "assert en_vocab[pad_token] == de_vocab[pad_token]\n",
    "\n",
    "unk_index = en_vocab[unk_token]\n",
    "pad_index = en_vocab[pad_token]\n",
    "\n",
    "en_vocab.set_default_index(unk_index)\n",
    "de_vocab.set_default_index(unk_index)\n",
    "\n",
    "def numericalize_example(example, en_vocab, de_vocab):\n",
    "    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n",
    "    de_ids = de_vocab.lookup_indices(example[\"de_tokens\"])\n",
    "    return {\"en_ids\": en_ids, \"de_ids\": de_ids}\n",
    "\n",
    "fn_kwargs = {\n",
    "\"en_vocab\": en_vocab, \n",
    "\"de_vocab\": de_vocab\n",
    "}\n",
    "\n",
    "train_data = train_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "valid_data = valid_data.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "test_data = test_data.map(numericalize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"numpy\"\n",
    "format_columns = [\"en_ids\", \"de_ids\"]\n",
    "\n",
    "train_data = train_data.with_format(\n",
    "    type=data_type, \n",
    "    columns=format_columns, \n",
    "    output_all_columns=True\n",
    ")\n",
    "\n",
    "valid_data = valid_data.with_format(\n",
    "    type=data_type, \n",
    "    columns=format_columns, \n",
    "    output_all_columns=True,\n",
    ")\n",
    "\n",
    "test_data = test_data.with_format(\n",
    "    type=data_type, \n",
    "    columns=format_columns, \n",
    "    output_all_columns=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(sequences:list, padding_value:int):\n",
    "    '''将序列填充到等长并返回mindspore张量'''\n",
    "    # Find the length of the longest sequence in the batch\n",
    "    max_length = max(len(seq) for seq in sequences)\n",
    "    padded_sequences:ms.Tensor = ops.full((len(sequences), max_length), padding_value, dtype=ms.int64)\n",
    "    # Copy the sequences into the padded array\n",
    "    for i, seq in enumerate(sequences):\n",
    "        padded_sequences[i, :len(seq)] = ms.tensor(seq).astype(np.int64)\n",
    "    # 换轴，保证输出为时序优先\n",
    "    padded_sequences = padded_sequences.swapaxes(0, 1)\n",
    "    return padded_sequences  \n",
    "\n",
    "def get_collate_fn(pad_index):\n",
    "    \n",
    "    def collate_fn(batch):\n",
    "        batch_en_ids = [example[\"en_ids\"] for example in batch]\n",
    "        batch_de_ids = [example[\"de_ids\"] for example in batch]\n",
    "        batch_en_ids = pad_sequence(batch_en_ids, padding_value=pad_index)\n",
    "        batch_de_ids = pad_sequence(batch_de_ids, padding_value=pad_index)\n",
    "        batch = {\n",
    "            \"en_ids\": batch_en_ids,\n",
    "            \"de_ids\": batch_de_ids,\n",
    "        }\n",
    "        return batch\n",
    "    \n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, source, batch_size, shuffle=False, per_batch_map=None):\n",
    "        self.source = source\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.per_batch_map = per_batch_map\n",
    "        self.indices = np.arange(len(source))\n",
    "        self.current_index = 0\n",
    "\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.current_index >= len(self.source):\n",
    "            self.current_index = 0\n",
    "            raise StopIteration\n",
    "\n",
    "        batch_indices = self.indices[self.current_index:self.current_index + self.batch_size]\n",
    "        batch_data = [self.source[int(i)] for i in batch_indices]\n",
    "\n",
    "        if self.per_batch_map:\n",
    "            batch_data = self.per_batch_map(batch_data)\n",
    "\n",
    "        self.current_index += self.batch_size\n",
    "        return batch_data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.source) // self.batch_size\n",
    "\n",
    "\n",
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    dataloader = DataLoader(dataset, batch_size, shuffle=shuffle, per_batch_map=collate_fn)\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型\n",
    "\n",
    "接下来是构建模型。与先前的模型一样，模型由编码器和解码器组成。编码器将输入句子（源语言中的句子）编码为上下文向量。解码器将上下文向量解码以生成目标语言中的输出句子。\n",
    "\n",
    "### 编码器\n",
    "\n",
    "这些教程中以前的模型中的编码器将整个输入句子压缩为单个上下文向量$z$。卷积序列到序列模型有点不同 - 它为输入句子中的每个标记获取两个上下文向量。因此，如果我们的输入句子有6个标记，我们将获得12个上下文向量，每个标记有两个。\n",
    "\n",
    "每个标记的两个上下文向量是*卷积*向量和*组合*向量。卷积向量是每个标记通过一些层传递的结果 - 我们将很快解释。组合向量来自卷积向量和该标记的嵌入的总和。编码器返回这两者供解码器使用。\n",
    "\n",
    "下面的图显示了将输入句子 - *zwei menschen fechten.* - 通过编码器的结果。\n",
    "\n",
    "![](assets/convseq2seq1.png)\n",
    "\n",
    "首先，通过*标记嵌入层*传递标记 - 这对于自然语言处理中的神经网络是标准的。然而，由于此模型中没有循环连接，因此它对序列中的标记的顺序一无所知。为了纠正这一点，我们有了第二个嵌入层，*位置嵌入层*。这是一个标准的嵌入层，其中的输入不是标记本身，而是标记在序列中的位置 - 从第一个标记，即<sos>（序列开始）标记开始，位置为0。\n",
    "\n",
    "接下来，标记和位置嵌入通过逐元素相加在一起，得到一个包含有关标记的信息以及其在序列中的位置的向量 - 我们简称为*嵌入向量*。然后是一个线性层，它将嵌入向量转换为所需的隐藏维度大小的向量。\n",
    "\n",
    "接下来的步骤是将此隐藏向量传递给$N$ *卷积块*。这是这个模型中的“魔法”发生的地方，我们将很快详细介绍卷积块的内容。通过卷积块传递后，然后将该向量通过另一个线性层馈送回，将其从隐藏维度大小转换回嵌入维度大小。这是我们的*卷积*向量 - 我们在输入序列中的每个标记上都有一个。\n",
    "\n",
    "最后，通过残差连接，将卷积向量逐元素与嵌入向量相加，得到每个标记的*组合*向量。同样，在输入序列中的每个标记都有一个组合向量。\n",
    "\n",
    "### 卷积块\n",
    "\n",
    "那么，这些卷积块是如何工作的呢？下图显示了带有单个过滤器（蓝色）的2个卷积块，该过滤器正在滑过序列中的标记。在实际实现中，我们将具有每个块中的1024个过滤器的10个卷积块。\n",
    "\n",
    "![](assets/convseq2seq2.png)\n",
    "\n",
    "首先，对输入句子进行了填充。这是因为卷积层将减小输入句子的长度，我们希望进入卷积块的序列的长度等于离开卷积块的序列的长度。如果不填充，通过卷积层输出的序列的长度将比输入卷积层的序列的长度短`filter_size - 1`。例如，如果我们的过滤器大小为3，则序列将短2个元素。因此，我们在每一侧填充句子一个填充元素。可以通过简单执行`(filter_size - 1)/2`来计算每一侧的填充量，对于奇数大小的过滤器，我们将不覆盖在此教程中介绍偶数大小的过滤器。\n",
    "\n",
    "这些过滤器设计成其输出的隐藏维度是输入隐藏维度的两倍。在计算机视觉术语中，这些隐藏维度称为*通道* - 但我们将坚持称之为隐藏维度。为什么在离开卷积滤波器时要将隐藏维度的大小加倍？这是因为我们使用了称为*门控线性单元*（GLU）的特殊激活函数。GLU在激活函数内部具有门控机制（类似于LSTM和GRU），实际上将隐藏维度的大小减半 - 而通常激活函数保持隐藏维度的大小不变。\n",
    "\n",
    "通过GLU激活后，每个标记的隐藏维度大小与进入卷积块时的大小相同。现在，它现在通过通过卷积层之前的自己的向量逐元素相加。\n",
    "\n",
    "这就结束了单个卷积块。随后的块获取上一个块的输出并执行相同的步骤。每个块都有自己的参数，它们在块之间不共享。最后一个块的输出返回到主编码器 - 在那里它通过线性层进行馈送，以获得卷积输出，然后通过嵌入标记的逐元素求和，以获得组合输出。\n",
    "\n",
    "### 编码器实现\n",
    "\n",
    "为了保持实现简单，我们只允许奇数大小的内核。这样可以使填充平均地添加到源序列的两侧。\n",
    "\n",
    "作者使用的`scale`变量用于“确保整个网络的方差不会发生剧烈变化”。如果不使用此变量，使用不同的种子时，模型的性能似乎会有很大的变化。\n",
    "\n",
    "位置嵌入的初始化具有100的“词汇表”。这意味着它可以处理长达100个元素的序列，从0到99索引。如果在具有更长序列的数据集上使用，可以增加此值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Cell):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 emb_dim, \n",
    "                 hid_dim, \n",
    "                 n_layers, \n",
    "                 kernel_size, \n",
    "                 dropout, \n",
    "                 max_length = 100):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert kernel_size % 2 == 1, \"Kernel size must be odd!\"\n",
    "        \n",
    "        \n",
    "        self.scale = ops.sqrt(ms.Tensor([0.5]).astype(ms.float32))\n",
    "        \n",
    "        self.tok_embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, emb_dim)\n",
    "        \n",
    "        self.emb2hid = nn.Dense(emb_dim, hid_dim)\n",
    "        self.hid2emb = nn.Dense(hid_dim, emb_dim)\n",
    "        \n",
    "        self.convs = nn.CellList([nn.Conv1d(in_channels = hid_dim, \n",
    "                                              pad_mode='pad',\n",
    "                                              out_channels = 2 * hid_dim, \n",
    "                                              kernel_size = kernel_size, \n",
    "                                              padding = (kernel_size - 1) // 2,\n",
    "                                              has_bias=True,)\n",
    "                                    for _ in range(n_layers)])\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def construct(self, src:ms.Tensor, pos):\n",
    "        #src = [batch size, src len]\n",
    "        batch_size = src.shape[0]\n",
    "        src_len = src.shape[1]\n",
    "        #create position tensor\n",
    "        # pos = ops.arange(0, src_len).unsqueeze(0).tile((batch_size, 1))\n",
    "        #pos = [0, 1, 2, 3, ..., src len - 1]\n",
    "        #pos = [batch size, src len]\n",
    "        #embed tokens and positions\n",
    "        tok_embedded = self.tok_embedding(src)\n",
    "        pos_embedded = self.pos_embedding(pos)\n",
    "        #tok_embedded = pos_embedded = [batch size, src len, emb dim]\n",
    "        #combine embeddings by elementwise summing\n",
    "        embedded = self.dropout(tok_embedded + pos_embedded)\n",
    "        #embedded = [batch size, src len, emb dim]\n",
    "        #pass embedded through linear layer to convert from emb dim to hid dim\n",
    "        conv_input = self.emb2hid(embedded)\n",
    "        #conv_input = [batch size, src len, hid dim]\n",
    "        #permute for convolutional layer\n",
    "        conv_input = conv_input.permute(0, 2, 1) \n",
    "        #conv_input = [batch size, hid dim, src len]\n",
    "        #begin convolutional blocks...\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            #pass through convolutional layer\n",
    "            conved = conv(self.dropout(conv_input))\n",
    "            #conved = [batch size, 2 * hid dim, src len]\n",
    "            #pass through GLU activation function\n",
    "            conved = ops.glu(conved, axis = 1)\n",
    "            #conved = [batch size, hid dim, src len]\n",
    "            #apply residual connection\n",
    "            conved = (conved + conv_input) * self.scale\n",
    "            #conved = [batch size, hid dim, src len]\n",
    "            #set conv_input to conved for next loop iteration\n",
    "            conv_input = conved\n",
    "        \n",
    "        #...end convolutional blocks\n",
    "        #permute and convert back to emb dim\n",
    "        conved = self.hid2emb(conved.permute(0, 2, 1))\n",
    "        #conved = [batch size, src len, emb dim]\n",
    "        #elementwise sum output (conved) and input (embedded) to be used for attention\n",
    "        combined = (conved + embedded) * self.scale\n",
    "        #combined = [batch size, src len, emb dim]\n",
    "        \n",
    "        return conved, combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解码器\n",
    "\n",
    "解码器接收实际的目标句子并尝试预测它。这个模型与先前在这些教程中详细说明的递归神经网络模型不同，因为它并行预测目标句子中的所有标记。没有顺序处理，即没有解码循环。这将在教程的后面详细说明。\n",
    "\n",
    "解码器类似于编码器，但在主模型和模型内部的卷积块中都有一些更改。\n",
    "\n",
    "![](assets/convseq2seq3.png)\n",
    "\n",
    "首先，嵌入没有连接到卷积块和变换后的残差连接。相反，嵌入被馈送到卷积块中，用作那里的残差连接。\n",
    "\n",
    "其次，为了从编码器中提供解码器信息，使用编码器的卷积和组合输出 - 同样，在卷积块中。\n",
    "\n",
    "最后，解码器的输出是从嵌入维度到输出维度的线性层。这用于对翻译中下一个单词应该是什么做出预测。\n",
    "\n",
    "### 解码器卷积块\n",
    "\n",
    "同样，这些与编码器内的卷积块相似，但有一些更改。\n",
    "\n",
    "![](assets/convseq2seq4.png)\n",
    "\n",
    "首先是填充。与编码器一样，我们在每一侧都填充相等，以确保整个句子的长度保持不变。在这里，我们只在句子的开头填充。由于我们同时并行处理所有目标，而不是顺序处理，因此我们需要一种方法，只允许将用于翻译标记$i$的过滤器仅查看标记$i$之前的标记。如果它们被允许查看标记$i+1$（它们应该输出的标记），则模型将简单地学会通过直接复制它来输出序列的下一个单词，而不实际学会如何翻译。\n",
    "\n",
    "让我们看看如果我们**错误地**在两侧均匀填充，就像在编码器中一样，会发生什么。\n",
    "\n",
    "![](assets/convseq2seq5.png)\n",
    "\n",
    "第一个位置的过滤器，试图使用序列中的第一个单词 `<sos>` 来预测第二个单词 `two`，现在直接可以看到单词 `two`。对于每个位置都是一样的，模型试图预测的单词是过滤器覆盖的第二个元素。因此，过滤器可以学会在每个位置简单地复制第二个单词，从而实现完美的翻译，而实际上并没有学会如何翻译。\n",
    "\n",
    "其次，在GLU激活之后，在残差连接之前，该块计算并应用注意力 - 使用编码表示和当前单词的嵌入。 **注意**：我们只显示与最右边的标记的连接，但它们实际上连接到所有标记 - 这是为了清晰起见。每个标记输入都使用自己的嵌入进行自己的注意力计算。\n",
    "\n",
    "注意力的计算首先使用线性层将隐藏维度更改为与嵌入维度相同的大小。然后通过残差连接进行嵌入。然后对这个组合进行标准的注意力计算，找出它与 *编码的卷积* 匹配了多少，然后通过 *编码的组合* 进行加权求和。然后将其投影回到隐藏维度大小，并将残差连接到注意力层的初始输入。\n",
    "\n",
    "为什么他们首先使用编码的卷积计算注意力，然后使用它来计算编码的组合上的加权和？论文认为，编码的卷积对获取编码序列上的更大上下文很有用，而编码的组合对特定标记具有更多信息，因此更有助于进行预测。\n",
    "\n",
    "### 解码器实现\n",
    "\n",
    "由于我们只在一侧进行填充，因此解码器可以使用奇数和偶数大小的填充。同样，`scale` 用于减小整个模型中的方差，位置嵌入被初始化为具有 \"词汇量\" 为100。\n",
    "\n",
    "这个模型在其 `construct` 方法中接收编码器表示，并且两者都被传递给 `calculate_attention` 方法，该方法计算并应用注意力。它还返回实际的注意力值，但我们目前没有使用它们。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Cell):\n",
    "    def __init__(self, \n",
    "                 output_dim, \n",
    "                 emb_dim, \n",
    "                 hid_dim, \n",
    "                 n_layers, \n",
    "                 kernel_size, \n",
    "                 dropout, \n",
    "                 trg_pad_idx, \n",
    "                 max_length = 100):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.hid_dim = hid_dim\n",
    "        \n",
    "        self.scale = ops.sqrt(ms.Tensor([0.5]).astype(ms.float32))\n",
    "        \n",
    "        self.tok_embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, emb_dim)\n",
    "        \n",
    "        self.emb2hid = nn.Dense(emb_dim, hid_dim)\n",
    "        self.hid2emb = nn.Dense(hid_dim, emb_dim)\n",
    "        \n",
    "        self.attn_hid2emb = nn.Dense(hid_dim, emb_dim)\n",
    "        self.attn_emb2hid = nn.Dense(emb_dim, hid_dim)\n",
    "        \n",
    "        self.fc_out = nn.Dense(emb_dim, output_dim)\n",
    "        \n",
    "        # self.padding_tensor = ops.ones((batch_size, \n",
    "        #                           hid_dim, \n",
    "        #                           self.kernel_size - 1)) * (self.trg_pad_idx)\n",
    "        \n",
    "        self.convs = nn.CellList([nn.Conv1d(in_channels = hid_dim, \n",
    "                                              out_channels = 2 * hid_dim, \n",
    "                                              pad_mode='pad',\n",
    "                                              kernel_size = kernel_size,\n",
    "                                              has_bias=True,)\n",
    "                                    for _ in range(n_layers)])\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "      \n",
    "    def calculate_attention(self, embedded:ms.Tensor, conved:ms.Tensor, encoder_conved:ms.Tensor, encoder_combined:ms.Tensor):\n",
    "        \n",
    "        #embedded = [batch size, trg len, emb dim]\n",
    "        #conved = [batch size, hid dim, trg len]\n",
    "        #encoder_conved = encoder_combined = [batch size, src len, emb dim]\n",
    "        \n",
    "        #permute and convert back to emb dim\n",
    "        conved_emb = self.attn_hid2emb(conved.permute(0, 2, 1))\n",
    "        \n",
    "        #conved_emb = [batch size, trg len, emb dim]\n",
    "        \n",
    "        combined = (conved_emb + embedded) * self.scale\n",
    "        \n",
    "        #combined = [batch size, trg len, emb dim]\n",
    "                \n",
    "        energy = ops.matmul(combined, encoder_conved.permute(0, 2, 1))\n",
    "        \n",
    "        #energy = [batch size, trg len, src len]\n",
    "        \n",
    "        attention = ops.softmax(energy, axis=2)\n",
    "        \n",
    "        #attention = [batch size, trg len, src len]\n",
    "            \n",
    "        attended_encoding = ops.matmul(attention, encoder_combined)\n",
    "        \n",
    "        #attended_encoding = [batch size, trg len, emd dim]\n",
    "        \n",
    "        #convert from emb dim -> hid dim\n",
    "        attended_encoding = self.attn_emb2hid(attended_encoding)\n",
    "        \n",
    "        #attended_encoding = [batch size, trg len, hid dim]\n",
    "        \n",
    "        #apply residual connection\n",
    "        attended_combined = (conved + attended_encoding.permute(0, 2, 1)) * self.scale\n",
    "        \n",
    "        #attended_combined = [batch size, hid dim, trg len]\n",
    "        \n",
    "        return attention, attended_combined\n",
    "        \n",
    "    def construct(self, trg:ms.Tensor, encoder_conved:ms.Tensor, encoder_combined:ms.Tensor, pos:ms.Tensor, pad:ms.Tensor):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        #encoder_conved = encoder_combined = [batch size, src len, emb dim]\n",
    "                \n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "            \n",
    "        #create position tensor\n",
    "        # pos = ops.arange(0, trg_len).unsqueeze(0).tile((batch_size, 1))\n",
    "        \n",
    "        #pos = [batch size, trg len]\n",
    "        \n",
    "        #embed tokens and positions\n",
    "        tok_embedded = self.tok_embedding(trg)\n",
    "        pos_embedded = self.pos_embedding(pos)\n",
    "        \n",
    "        #tok_embedded = [batch size, trg len, emb dim]\n",
    "        #pos_embedded = [batch size, trg len, emb dim]\n",
    "        \n",
    "        #combine embeddings by elementwise summing\n",
    "        embedded = self.dropout(tok_embedded + pos_embedded)\n",
    "        \n",
    "        #embedded = [batch size, trg len, emb dim]\n",
    "        \n",
    "        #pass embedded through linear layer to go through emb dim -> hid dim\n",
    "        conv_input = self.emb2hid(embedded)\n",
    "        \n",
    "        #conv_input = [batch size, trg len, hid dim]\n",
    "        \n",
    "        #permute for convolutional layer\n",
    "        conv_input = conv_input.permute(0, 2, 1) \n",
    "        \n",
    "        #conv_input = [batch size, hid dim, trg len]\n",
    "        \n",
    "        batch_size = conv_input.shape[0]\n",
    "        hid_dim = conv_input.shape[1]\n",
    "        \n",
    "        for i, conv in enumerate(self.convs):\n",
    "        \n",
    "            #apply dropout\n",
    "            conv_input = self.dropout(conv_input)\n",
    "        \n",
    "            #need to pad so decoder can't \"cheat\"\n",
    "            # padding = ops.ones((batch_size, \n",
    "            #                       hid_dim, \n",
    "            #                       self.kernel_size - 1)) * (self.trg_pad_idx)\n",
    "                \n",
    "            padded_conv_input = ops.cat((pad, conv_input), axis = 2)\n",
    "        \n",
    "            #padded_conv_input = [batch size, hid dim, trg len + kernel size - 1]\n",
    "        \n",
    "            #pass through convolutional layer\n",
    "            conved = conv(padded_conv_input)\n",
    "            #conved = [batch size, 2 * hid dim, trg len]\n",
    "            #pass through GLU activation function\n",
    "            conved = ops.glu(conved, axis = 1)\n",
    "            #conved = [batch size, hid dim, trg len]\n",
    "            \n",
    "            #calculate attention\n",
    "            attention, conved = self.calculate_attention(embedded, \n",
    "                                                         conved, \n",
    "                                                         encoder_conved, \n",
    "                                                         encoder_combined)\n",
    "            \n",
    "            #attention = [batch size, trg len, src len]\n",
    "            \n",
    "            #apply residual connection\n",
    "            conved = (conved + conv_input) * self.scale\n",
    "            \n",
    "            #conved = [batch size, hid dim, trg len]\n",
    "            \n",
    "            #set conv_input to conved for next loop iteration\n",
    "            conv_input = conved\n",
    "            \n",
    "        conved = self.hid2emb(conved.permute(0, 2, 1))\n",
    "         \n",
    "        #conved = [batch size, trg len, emb dim]\n",
    "            \n",
    "        output = self.fc_out(self.dropout(conved))\n",
    "        \n",
    "        #output = [batch size, trg len, output dim]\n",
    "            \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq\n",
    "\n",
    "封装的`Seq2Seq`模块与先前笔记本中使用的递归神经网络方法非常不同，特别是在解码部分。\n",
    "\n",
    "我们的`trg`序列末尾被切掉了`<eos>`元素。这是因为我们不会将`<eos>`标记输入解码器。\n",
    "\n",
    "编码类似，将源序列插入并接收“上下文向量”。但是，在这里，我们每个单词的源序列有两个上下文向量，`encoder_conved`和`encoder_combined`。\n",
    "\n",
    "由于解码是并行进行的，我们不需要解码循环。整个目标序列一次输入解码器，并且填充用于确保解码器中的每个卷积过滤器在滑过句子时只能看到当前标记和前一个标记。\n",
    "\n",
    "但是，这也意味着我们不能使用这个模型进行teacher forcing。我们没有循环，可以选择是输入预测的标记还是实际标记到序列中，因为所有内容都是并行预测的。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Cell):\n",
    "    def __init__(self, encoder:Encoder, decoder:Decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def construct(self, src, trg, enc_pos_vec, dec_pos_vec, dec_pad_vec):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #trg = [batch size, trg len - 1] (<eos> token sliced off the end)\n",
    "           \n",
    "        #calculate z^u (encoder_conved) and (z^u + e) (encoder_combined)\n",
    "        #encoder_conved is output from final encoder conv. block\n",
    "        #encoder_combined is encoder_conved plus (elementwise) src embedding plus \n",
    "        #  positional embeddings \n",
    "        encoder_conved, encoder_combined = self.encoder(src, enc_pos_vec)\n",
    "            \n",
    "        #encoder_conved = [batch size, src len, emb dim]\n",
    "        #encoder_combined = [batch size, src len, emb dim]\n",
    "        \n",
    "        #calculate predictions of next words\n",
    "        #output is a batch of predictions for each word in the trg sentence\n",
    "        #attention a batch of attention scores across the src sentence for \n",
    "        #  each word in the trg sentence\n",
    "        output, attention = self.decoder(trg, encoder_conved, encoder_combined, dec_pos_vec, dec_pad_vec)\n",
    "        \n",
    "        #output = [batch size, trg len - 1, output dim]\n",
    "        #attention = [batch size, trg len - 1, src len]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(de_vocab)\n",
    "OUTPUT_DIM = len(en_vocab)\n",
    "EMB_DIM = 256\n",
    "HID_DIM = 512 # each conv. layer has 2 * hid_dim filters\n",
    "ENC_LAYERS = 10 # number of conv. blocks in encoder\n",
    "DEC_LAYERS = 10 # number of conv. blocks in decoder\n",
    "ENC_LAYERS = 10 # number of conv. blocks in encoder\n",
    "DEC_LAYERS = 10 # number of conv. blocks in decoder\n",
    "ENC_KERNEL_SIZE = 3 # must be odd!\n",
    "DEC_KERNEL_SIZE = 3 # can be even or odd\n",
    "ENC_DROPOUT = 0.25\n",
    "DEC_DROPOUT = 0.25\n",
    "SRC_PAD_IDX = de_vocab.get_stoi()[pad_token]\n",
    "TRG_PAD_IDX = en_vocab.get_stoi()[pad_token]\n",
    "\n",
    "\n",
    "enc = Encoder(INPUT_DIM, EMB_DIM, HID_DIM, ENC_LAYERS, ENC_KERNEL_SIZE, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, EMB_DIM, HID_DIM, DEC_LAYERS, DEC_KERNEL_SIZE, DEC_DROPOUT, TRG_PAD_IDX)\n",
    "\n",
    "model = Seq2Seq(enc, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 37,351,173 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.get_parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们定义优化器和损失函数（criterion）。与之前一样，我们在目标序列包含填充标记的地方忽略损失。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = nn.Adam(model.trainable_params())\n",
    "# optimizer = nn.Adam(model.trainable_params(), learning_rate=0.001)  # 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们为模型定义训练循环。\n",
    "\n",
    "我们处理序列的方式与以前的教程有些不同。对于所有模型，我们都不将 `<eos>` 放入解码器。在 RNN 模型中，通过使解码器循环不包含 `<eos>` 作为解码器的输入来处理这个问题。在这个模型中，我们简单地在序列的末尾切片 `<eos>` 标记。因此：\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{trg} &= [\\text{sos}, x_1, x_2, x_3, \\text{eos}]\\\\\n",
    "\\text{trg[:-1]} &= [\\text{sos}, x_1, x_2, x_3]\n",
    "\\end{align*}$$\n",
    "\n",
    "其中，$x_i$ 表示实际目标序列元素。然后，我们将其馈送到模型中，以获得一个预测的序列，希望能够预测 `<eos>` 标记：\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{output} &= [y_1, y_2, y_3, \\text{eos}]\n",
    "\\end{align*}$$\n",
    "\n",
    "其中，$y_i$ 表示预测的目标序列元素。然后，我们使用原始 `trg` 张量计算损失，其中 `<sos>` 标记从前面切片掉，只留下 `<eos>` 标记：\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\text{output} &= [y_1, y_2, y_3, \\text{eos}]\\\\\n",
    "\\text{trg[1:]} &= [x_1, x_2, x_3, \\text{eos}]\n",
    "\\end{align*}$$\n",
    "\n",
    "然后，我们计算损失并按照标准更新参数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_fn(src:ms.Tensor, trg:ms.Tensor, enc_pos_vec, dec_pos_vec, dec_pad_vec):\n",
    "    \n",
    "    output, _ = model(src, trg[:,:-1], enc_pos_vec, dec_pos_vec, dec_pad_vec)\n",
    "    #output = [batch size, trg len - 1, output dim]\n",
    "    #trg = [batch size, trg len]\n",
    "    output_dim = output.shape[-1]\n",
    "    output = output.reshape(-1, output_dim)\n",
    "    trg = trg[:,1:].reshape(-1)\n",
    "    #output = [batch size * trg len - 1, output dim]\n",
    "    #trg = [batch size * trg len - 1]\n",
    "    loss = criterion(output, trg.astype(ms.int32))\n",
    "    return loss\n",
    "\n",
    "grad_fn = ms.value_and_grad(forward_fn, grad_position=None, weights=model.trainable_params())\n",
    "\n",
    "\n",
    "\n",
    "def train(iterator, optimizer, clip):\n",
    "    model.set_train(True)\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(tqdm(iterator)):\n",
    "        src = batch[\"de_ids\"]\n",
    "        trg = batch[\"en_ids\"]\n",
    "        src = src.swapaxes(0,1)\n",
    "        trg = trg.swapaxes(0,1)\n",
    "\n",
    "        trg_batch_size = trg.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        src_batch_size = src.shape[0]\n",
    "        src_len = src.shape[1]\n",
    "\n",
    "        pos_enc = ops.arange(0, src_len).unsqueeze(0).tile((src_batch_size, 1))\n",
    "        pos_dec = ops.arange(0, trg_len - 1).unsqueeze(0).tile((trg_batch_size, 1))\n",
    "        pad_dec = ops.ones((trg_batch_size, model.decoder.hid_dim, model.decoder.kernel_size - 1)) * (model.decoder.trg_pad_idx)\n",
    "        \n",
    "        loss, grads = grad_fn(src, trg, pos_enc, pos_dec, pad_dec)\n",
    "        # grads = ops.clip_by_norm(grads, max_norm=clip)\n",
    "        optimizer(grads)\n",
    "        epoch_loss += float(loss)\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model:Seq2Seq, iterator, criterion):\n",
    "    \n",
    "    model.set_train(False)\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "\n",
    "        src = batch[\"de_ids\"]\n",
    "        trg = batch[\"en_ids\"]\n",
    "        src = src.swapaxes(0,1)\n",
    "        trg = trg.swapaxes(0,1)\n",
    "\n",
    "        trg_batch_size = trg.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        src_batch_size = src.shape[0]\n",
    "        src_len = src.shape[1]\n",
    "\n",
    "        pos_enc = ops.arange(0, src_len).unsqueeze(0).tile((src_batch_size, 1))\n",
    "        pos_dec = ops.arange(0, trg_len - 1).unsqueeze(0).tile((trg_batch_size, 1))\n",
    "        pad_dec = ops.ones((trg_batch_size, model.decoder.hid_dim, model.decoder.kernel_size - 1)) * (model.decoder.trg_pad_idx)\n",
    "\n",
    "        output, _ = model(src, trg[:,:-1], pos_enc, pos_dec, pad_dec)\n",
    "    \n",
    "        #output = [batch size, trg len - 1, output dim]\n",
    "        #trg = [batch size, trg len]\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output.view(-1, output_dim)\n",
    "        trg = trg[:,1:].view(-1)\n",
    "\n",
    "        #output = [batch size * trg len - 1, output dim]\n",
    "        #trg = [batch size * trg len - 1]\n",
    "        \n",
    "        loss = criterion(output, trg.astype(ms.int32))\n",
    "        epoch_loss += float(loss)\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们训练我们的模型。请注意，我们已将 `CLIP` 值从 1 降低到 0.1，以便更可靠地训练此模型。使用较高的 `CLIP` 值时，梯度偶尔会爆炸。\n",
    "\n",
    "尽管我们的参数比基于注意力的 RNN 模型多了近一倍，但实际上它花费的时间大约是标准版本的一半，与使用第四章版本的时间大致相同。这是因为所有计算都是使用卷积滤波器并行完成的，而不是使用 RNN 顺序完成的。\n",
    "\n",
    "**注意**：此模型的强制教学率始终为 1，即它将始终使用目标序列中的实际下一个标记。这意味着我们无法将 perplexity 值与先前的模型进行比较，因为它们使用的强制教学率不是 1。请参阅[此处](https://github.com/bentrevett/pytorch-seq2seq/issues/39#issuecomment-529408483)，了解使用教师强制比率为 1 时基于注意力的 RNN 的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2236b74d5248c38c52f0431151cd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 57s\n",
      "\tTrain Loss:   4.956 | Train PPL: 142.017\n",
      "\tValid Loss:   4.579 | Valid PPL:  97.458\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e04ac5bf43b4a958e8952e6c3dd257e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 56s\n",
      "\tTrain Loss:   3.939 | Train PPL:  51.390\n",
      "\tValid Loss:   4.052 | Valid PPL:  57.532\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067ff820772c4c68a3f847ceec4fd640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 56s\n",
      "\tTrain Loss:   3.491 | Train PPL:  32.821\n",
      "\tValid Loss:   3.417 | Valid PPL:  30.491\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9b3296ab9c4a4e83464aca107a5ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 56s\n",
      "\tTrain Loss:   2.962 | Train PPL:  19.343\n",
      "\tValid Loss:   2.921 | Valid PPL:  18.559\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3459b70cd77a4c6b88137f572855f1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 1m 3s\n",
      "\tTrain Loss:   2.564 | Train PPL:  12.990\n",
      "\tValid Loss:   2.583 | Valid PPL:  13.231\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6e608b09854edebbb82e729dd535f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 1m 2s\n",
      "\tTrain Loss:   2.279 | Train PPL:   9.766\n",
      "\tValid Loss:   2.372 | Valid PPL:  10.721\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8754544c2cc942608ebe92b4fd7dcf62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 1m 0s\n",
      "\tTrain Loss:   2.058 | Train PPL:   7.831\n",
      "\tValid Loss:   2.209 | Valid PPL:   9.106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b86a014b14438cb5190ada6cbe176d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 1m 1s\n",
      "\tTrain Loss:   1.887 | Train PPL:   6.597\n",
      "\tValid Loss:   2.110 | Valid PPL:   8.251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4262a7217c54892a48fcdfca5d45d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 1m 0s\n",
      "\tTrain Loss:   1.746 | Train PPL:   5.731\n",
      "\tValid Loss:   2.056 | Valid PPL:   7.818\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad29ff833852478d9422cb3718f4c3e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 1m 0s\n",
      "\tTrain Loss:   1.638 | Train PPL:   5.143\n",
      "\tValid Loss:   2.030 | Valid PPL:   7.613\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 0.1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(train_data_loader, optimizer, CLIP)\n",
    "    valid_loss = evaluate(model, valid_data_loader, criterion)\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        ms.save_checkpoint(model, f\"./tut5-model.ckpt\")     \n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，我们加载获得最低验证损失的网络参数，并计算在测试集上的损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 2.108 | Test PPL:   8.232 |\n"
     ]
    }
   ],
   "source": [
    "ms.load_checkpoint(f\"tut5-model.ckpt\", model)\n",
    "\n",
    "test_loss = evaluate(model, test_data_loader, criterion)\n",
    "\n",
    "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们可以使用下面的 `translate_sentence` 函数从我们的模型中得到翻译。\n",
    "\n",
    "执行步骤如下：\n",
    "- 对源句子进行标记化（如果尚未标记化）\n",
    "- 添加 `<sos>` 和 `<eos>` 标记\n",
    "- 数字化源句子\n",
    "- 将其转换为张量并添加一个批次维度\n",
    "- 将源句子输入编码器\n",
    "- 创建一个列表以保存输出句子，初始化为 `<sos>` 标记\n",
    "- 当未达到最大长度时\n",
    "  - 将当前输出句子预测转换为带有批次维度的张量\n",
    "  - 将当前输出和两个编码器输出放入解码器\n",
    "  - 从解码器获取下一个输出标记预测\n",
    "  - 将预测添加到当前输出句子预测中\n",
    "  - 如果预测是 `<eos>` 标记，则中断\n",
    "- 将输出句子从索引转换为标记\n",
    "- 返回输出句子（删除 `<sos>` 标记）和来自最后一层的注意力\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(\n",
    "    sentence, \n",
    "    model:Seq2Seq,\n",
    "    en_nlp:spacy.Language,\n",
    "    de_nlp:spacy.Language,\n",
    "    en_vocab:Vocab,\n",
    "    de_vocab:Vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    max_output_length=25,\n",
    "):\n",
    "    model.set_train(False)\n",
    "    if isinstance(sentence, str):\n",
    "        tokens = [token.text for token in de_nlp.tokenizer(sentence)]\n",
    "    else:\n",
    "        tokens = [token for token in sentence]\n",
    "    if lower:\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "    tokens = [sos_token] + tokens + [eos_token]\n",
    "    ids = de_vocab.lookup_indices(tokens)\n",
    "\n",
    "    tensor = ms.Tensor(ids).astype(ms.int64).unsqueeze(0)\n",
    "    # 输入位置编码\n",
    "    pos_enc = ops.arange(0, len(ids)).unsqueeze(0).tile((1, 1))\n",
    "    encoder_conved, encoder_combined = model.encoder(tensor, pos_enc)\n",
    "    inputs = en_vocab.lookup_indices([sos_token])\n",
    "\n",
    "    \n",
    "    for i in range(max_output_length):\n",
    "        inputs_tensor = ms.Tensor(inputs).unsqueeze(0).astype(ms.int64)\n",
    "        # 输出位置编码，# 填充矩阵\n",
    "        pos_dec = ops.arange(0, len(inputs_tensor)).unsqueeze(0).tile((1, 1))\n",
    "        pad_dec = ops.ones((1, model.decoder.hid_dim, model.decoder.kernel_size - 1)) * (model.decoder.trg_pad_idx)\n",
    "        output, attention = model.decoder(inputs_tensor, encoder_conved, encoder_combined, pos_dec, pad_dec)\n",
    "        predicted_token = output.argmax(2)[:,-1].item()\n",
    "        inputs.append(int(predicted_token))\n",
    "        if predicted_token == en_vocab[eos_token]:\n",
    "            break\n",
    "    en_tokens = en_vocab.lookup_tokens(inputs)\n",
    "    return en_tokens, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.',\n",
       " 'A man in an orange hat starring at something.')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = test_data[0][\"de\"]\n",
    "expected_translation = test_data[0][\"en\"]\n",
    "\n",
    "sentence, expected_translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，我们将其传递到我们的 `translate_sentence` 函数中，该函数会给出预测的翻译标记以及注意力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'a',\n",
       " 'man',\n",
       " 'in',\n",
       " 'an',\n",
       " 'orange',\n",
       " 'hat',\n",
       " 'is',\n",
       " '<unk>',\n",
       " 'something',\n",
       " '<unk>',\n",
       " '.',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation, attention = translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    de_nlp,\n",
    "    en_vocab,\n",
    "    de_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    ")\n",
    "translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们编写如下函数，将显示模型在解码的每个步骤中对每个输入标记的关注程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_attention(sentence, translation, attention):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "        \n",
    "    attention = attention.squeeze(0).numpy()\n",
    "    \n",
    "    cax = ax.matshow(attention, cmap='bone')\n",
    "    if isinstance(sentence, str):\n",
    "            tokens = [token.text for token in de_nlp.tokenizer(sentence)]\n",
    "    else:\n",
    "        tokens = [token for token in sentence]\n",
    "    if lower:\n",
    "        tokens = [token.lower() for token in tokens]\n",
    "\n",
    "    x_ticks = [''] + ['<sos>'] + tokens + ['<eos>']\n",
    "    \n",
    "    ax.tick_params(labelsize=15)\n",
    "    ax.set_xticklabels(x_ticks, rotation=45)\n",
    "    ax.set_yticklabels(['']+translation)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以查看模型的注意力，确保它给出合理的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "/root/.local/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: FixedFormatter should only be used together with FixedLocator\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_attention(sentence, translation, attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过将任何字符串传递给 `translate_sentence` 来使用它来翻译任意句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>',\n",
       " 'a',\n",
       " 'man',\n",
       " 'is',\n",
       " 'looking',\n",
       " 'at',\n",
       " 'a',\n",
       " 'movie',\n",
       " 'machine',\n",
       " '.',\n",
       " '<eos>']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Ein Mann sieht sich einen Film an.\"\n",
    "translation, attention = translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    de_nlp,\n",
    "    en_vocab,\n",
    "    de_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    ")\n",
    "translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEU\n",
    "\n",
    "以前我们只关心模型的损失/困惑度。然而，有一些专门用于测量翻译质量的指标 - 最流行的是 *BLEU*。不详细介绍，BLEU 从 n-gram 的角度考察了预测目标序列与实际目标序列的重叠程度。它会给我们每个序列一个介于 0 和 1 之间的数字，其中 1 表示完全重叠，即完美翻译，尽管通常显示在 0 和 100 之间。BLEU 最初是为每个源序列有多个候选翻译设计的，但在这个数据集中，每个源序列只有一个候选翻译。\n",
    "\n",
    "我们从`evaluate`库中加载BLEU指标： 它用来计算数据集上的 BLEU 分数。该函数为每个源语句创建了实际翻译和预测翻译的语料库，然后计算 BLEU 分数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e96bf547b33450da90f5412e2d2c758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e395a437b3437d8042195465ba7a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e5815ac3564be293405bda6d307ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bleu = evaluate_hf.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "循环遍历我们的 `test_data`，得到模型对每个测试句子的翻译。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd5d8c60cd046ad999e03131cc6821f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translations = [\n",
    "    translate_sentence(\n",
    "        example[\"de\"],\n",
    "        model,\n",
    "        en_nlp,\n",
    "        de_nlp,\n",
    "        en_vocab,\n",
    "        de_vocab,\n",
    "        lower,\n",
    "        sos_token,\n",
    "        eos_token, \n",
    "    )[0] for example in tqdm(test_data)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [\n",
    "    \" \".join(translation[1:-1]) for translation in translations\n",
    "]\n",
    "\n",
    "references = [\n",
    "    [example[\"en\"]] for example in test_data\n",
    "]\n",
    "\n",
    "def get_tokenizer_fn(nlp, lower):\n",
    "    \n",
    "    def tokenizer_fn(s):\n",
    "        tokens = [token.text for token in nlp.tokenizer(s)]\n",
    "        if lower:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        return tokens\n",
    "        \n",
    "    return tokenizer_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.18870662757692383,\n",
       " 'precisions': [0.3744122965641953,\n",
       "  0.2359848484848485,\n",
       "  0.14905566600397616,\n",
       "  0.09628661087866108],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.6939807014856794,\n",
       " 'translation_length': 22120,\n",
       " 'reference_length': 13058}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_fn = get_tokenizer_fn(en_nlp, lower)\n",
    "results = bleu.compute(predictions=predictions, references=references, tokenizer=tokenizer_fn)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
